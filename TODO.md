# TODO

- [X] either make a script to add an entry in the dataset or just doucemnt the command to do it.
- [X] diff computation
- [X] Make the dataset with a python script
- [X] refactor dataset creation
- [X] change diff computation
- [X] refactor run-evaluation
  - [X] Use vllm and openai inference via a wrapper for evaluation(get inspired by https://github.com/HumanEval-V/HumanEval-V-Benchmark/blob/main/models/vllm_model.py)
- [X] Finish implementing openai batch api
- [X] Add an api option for run evaluation
- [X] Make a score object and change the evaluator to return it (change the tests as well)
- [X] Remake latex-Compiler
- [X] Make some first simple data
- [X] text squid, find other possible solutions for dataset
- [ ] implement pass@k
- [ ] Add vision input possibility in model class (both vllm and openai->https://platform.openai.com/docs/guides/vision)
- [ ] Create synthetic data
- [ ] ascii art "compiler"
- [ ] github action
  - [ ] creates and publishes the dataset
- [ ] Add a config file containing vllm config 
