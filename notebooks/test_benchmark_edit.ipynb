{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are an image classification agent. Your role is to evaluate whether a given instruction has been correctly applied to an image.\n",
    "You are given the modified image and an instruction.\n",
    " Response Format:\n",
    "1. Provide a step-by-step analysis of the image in relation to the instruction.  \n",
    "2. Conclude your response with either `<YES>` or `<NO>` on a new line, depending on whether the instruction was applied.  \n",
    "3. Ensure that `<YES>` or `<NO>` is enclosed within less than (`<`) and greater than (`>`) signs and appears on a separate line at the end of the response.  \n",
    "4. Ensure the less than (`<`) and greater than (`>`) signs are only used at the end of the response and nowhere else.\n",
    "\n",
    "Was the instruction \"{instruction}\" applied to the image?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "     base_url=\"https://api.groq.com/openai/v1\", api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def assess_response(response: str) -> bool:\n",
    "    matches = re.search(r\"<(.{3})>\", response)\n",
    "    if not matches:\n",
    "        return \"<YES>\" in response\n",
    "    return matches.group(1) == \"YES\"\n",
    "\n",
    "\n",
    "def check_modification(\n",
    "    image_solution: Image.Image, instruction: str#, image_input: Image.Image\n",
    ") -> bool:\n",
    "    #buffered_input = BytesIO()\n",
    "    #image_input.save(buffered_input, format=\"JPEG\")\n",
    "    #img_str_input = base64.b64encode(buffered_input.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    buffered_solution = BytesIO()\n",
    "    image_solution.save(buffered_solution, format=\"JPEG\")\n",
    "    img_str_solution = base64.b64encode(buffered_solution.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "         model=\"llama-3.2-90b-vision-preview\",\n",
    "        #model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            #{\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": PROMPT.format(instruction=instruction)\n",
    "                    },\n",
    "                    #{\n",
    "                    #    \"type\": \"image_url\",\n",
    "                    #    \"image_url\": {\n",
    "                    #        \"url\": f\"data:image/jpeg;base64,{img_str_input}\",\n",
    "                    #        \"detail\": \"low\",\n",
    "                    #    },\n",
    "                    #},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{img_str_solution}\",\n",
    "                            \"detail\": \"low\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_completion_tokens=4096,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    return assess_response(response), response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating against the right solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [05:06<00:00,  3.06s/ examples]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def classification(row):\n",
    "    row[\"instruction_applied\"],row[\"response\"] = check_modification(row[\"image_solution\"][0],row[\"instruction\"],row[\"image_input\"])\n",
    "    return row\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"CharlyR/varbench\", \"tikz\", split=\"benchmark\")\n",
    "\n",
    "ds = ds.select_columns([\"id\",\"instruction\",\"image_solution\",\"image_input\"])\n",
    "\n",
    "ds = ds.map(classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 6847.62 examples/s]t/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 166.57ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/CharlyR/vTikz-vlm_oracl_benchmark/commit/c18c623f552654b99226f18344850e71f48f23d9', commit_message='Upload dataset', commit_description='', oid='c18c623f552654b99226f18344850e71f48f23d9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/CharlyR/vTikz-vlm_oracl_benchmark', endpoint='https://huggingface.co', repo_type='dataset', repo_id='CharlyR/vTikz-vlm_oracl_benchmark'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(\"CharlyR/vTikz-vlm_oracl_benchmark\",\"input_provided_gpt4o-mini\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 100/100 [00:00<00:00, 10380.66 examples/s]\n",
      "Generating test split: 100%|██████████| 100/100 [00:00<00:00, 9784.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vlm_dataset = load_dataset(\"CharlyR/vTikz-vlm_oracl_benchmark\",\"default\", split=\"test\")\n",
    "input_provided_dataset = load_dataset(\"CharlyR/vTikz-vlm_oracl_benchmark\",\"input_provided_gpt4o-mini\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "vlm_df  = vlm_dataset.to_pandas()\n",
    "\n",
    "print(len(vlm_df[vlm_df[\"instruction_applied\"]==True]))\n",
    "\n",
    "input_provided_df  = input_provided_dataset.to_pandas()\n",
    "print(len(input_provided_df[input_provided_df[\"instruction_applied\"]==True]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating against a wrong solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"CharlyR/varbench\", \"tikz\", split=\"benchmark\")\n",
    "\n",
    "ds = ds.select_columns([\"id\",\"instruction\",\"image_solution\",\"image_input\",\"code\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>instruction</th>\n",
       "      <th>image_solution</th>\n",
       "      <th>image_input</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beam_coord_change</td>\n",
       "      <td>Move the coordinate system between EA and F.</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5pt]{standalone}\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bee_eyes</td>\n",
       "      <td>Add eyes to the bee with pupils, on the front ...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bee_longer_body</td>\n",
       "      <td>Make the body of the bee longer, and pointy</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bee_mirrored</td>\n",
       "      <td>Mirror the bee vertically</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bee_red_stripes</td>\n",
       "      <td>Change the color of the stripes to red</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>vima_no_256</td>\n",
       "      <td>Remove the measurements for 256kb</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>vr_two_motors</td>\n",
       "      <td>Split the motors into two motors next to eacho...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>workflow_box_label</td>\n",
       "      <td>Add a label k_n to each filled black rectangle...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>workflow_loop_removed</td>\n",
       "      <td>Remove the entire bottom section of the diagra...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>zoomedtriangle_centered</td>\n",
       "      <td>Center the zoom at the green intersection point.</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>\\documentclass[tikz,border=5]{standalone}\\n\\us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0         beam_coord_change   \n",
       "1                  bee_eyes   \n",
       "2           bee_longer_body   \n",
       "3              bee_mirrored   \n",
       "4           bee_red_stripes   \n",
       "..                      ...   \n",
       "95              vima_no_256   \n",
       "96            vr_two_motors   \n",
       "97       workflow_box_label   \n",
       "98    workflow_loop_removed   \n",
       "99  zoomedtriangle_centered   \n",
       "\n",
       "                                          instruction  \\\n",
       "0        Move the coordinate system between EA and F.   \n",
       "1   Add eyes to the bee with pupils, on the front ...   \n",
       "2         Make the body of the bee longer, and pointy   \n",
       "3                           Mirror the bee vertically   \n",
       "4              Change the color of the stripes to red   \n",
       "..                                                ...   \n",
       "95                  Remove the measurements for 256kb   \n",
       "96  Split the motors into two motors next to eacho...   \n",
       "97  Add a label k_n to each filled black rectangle...   \n",
       "98  Remove the entire bottom section of the diagra...   \n",
       "99   Center the zoom at the green intersection point.   \n",
       "\n",
       "                                       image_solution  \\\n",
       "0   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "1   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "2   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "3   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "4   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "..                                                ...   \n",
       "95  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "96  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "97  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "98  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "99  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "\n",
       "                                          image_input  \\\n",
       "0   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "1   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "2   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "3   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "4   {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "..                                                ...   \n",
       "95  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "96  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "97  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "98  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "99  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "\n",
       "                                                 code  \n",
       "0   \\documentclass[tikz,border=5pt]{standalone}\\n\\...  \n",
       "1   \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "2   \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "3   \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "4   \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "..                                                ...  \n",
       "95  \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "96  \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "97  \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "98  \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "99  \\documentclass[tikz,border=5]{standalone}\\n\\us...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas\n",
    "df = ds.to_pandas()\n",
    "\n",
    "df[\"image_solution\"] = df[\"image_solution\"].apply(lambda x:x[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20947/3131028574.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_full = df.groupby(\"code\", group_keys=False).apply(compute_non_values)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Compute non_values\n",
    "def compute_non_values(group: pd.DataFrame):\n",
    "    all_solutions = group[\"image_solution\"].tolist()\n",
    "\n",
    "    def add_wrong_solutions(row):\n",
    "        current_solution = row[\"image_solution\"]\n",
    "        removed_solution = all_solutions.copy()\n",
    "        removed_solution.remove(current_solution)\n",
    "        row[\"wrong_solutions\"] = removed_solution\n",
    "        return row\n",
    "\n",
    "    group =  group.apply(add_wrong_solutions,axis=1)\n",
    "    return group\n",
    "\n",
    "\n",
    "df_full = df.groupby(\"code\", group_keys=False).apply(compute_non_values)\n",
    "df_full = df_full.explode([\"wrong_solutions\"])\n",
    "df_full = df_full.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display(row):\n",
    "    print(row[\"instruction\"])  # Display the instruction text\n",
    "    \n",
    "    # Extract and open images\n",
    "    input_data = row[\"image_input\"]\n",
    "    input_image = Image.open(io.BytesIO(input_data[\"bytes\"]))\n",
    "    \n",
    "    wrong_data = row[\"wrong_solutions\"]\n",
    "    wrong_image = Image.open(io.BytesIO(wrong_data[\"bytes\"]))\n",
    "    \n",
    "    right_data = row[\"image_solution\"]\n",
    "    right_image = Image.open(io.BytesIO(right_data[\"bytes\"]))\n",
    "\n",
    "    # Create a figure with 3 subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Display images\n",
    "    axes[0].imshow(input_image)\n",
    "    axes[0].set_title(\"Input Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(wrong_image)\n",
    "    axes[1].set_title(\"Wrong Solution\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(right_image)\n",
    "    axes[2].set_title(\"Right Solution\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.show() \n",
    "    \n",
    "    \n",
    "entry = df_full.iloc[i]\n",
    "display(entry)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execute classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.Dataset.from_pandas(df_full)\n",
    "ds = (\n",
    "    ds.cast_column(\"image_input\", datasets.Image(decode=True))\n",
    "    .cast_column(\"image_solution\", datasets.Image(decode=True))\n",
    "    .cast_column(\"wrong_solutions\", datasets.Image(decode=True))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 232/232 [04:34<00:00,  1.18s/ examples]\n"
     ]
    }
   ],
   "source": [
    "def classification(row):\n",
    "    row[\"instruction_applied\"],row[\"response\"] = check_modification(row[\"wrong_solutions\"],row[\"instruction\"])\n",
    "    return row\n",
    "ds = ds.map(classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 232/232 [00:00<00:00, 7833.00 examples/s]t/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 318.85ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/CharlyR/vTikz-vlm_oracl_benchmark/commit/e9cdfa2f2a8a6173185e62c32690056efab661e5', commit_message='Upload dataset', commit_description='', oid='e9cdfa2f2a8a6173185e62c32690056efab661e5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/CharlyR/vTikz-vlm_oracl_benchmark', endpoint='https://huggingface.co', repo_type='dataset', repo_id='CharlyR/vTikz-vlm_oracl_benchmark'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ds.push_to_hub(\"CharlyR/vTikz-vlm_oracl_benchmark\",\"input_provided_gpt4o-mini_wrong_solution\", split=\"test\")\n",
    "ds.push_to_hub(\"CharlyR/vTikz-vlm_oracl_benchmark\",\"llama90bvision_wrong_solution\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 232/232 [00:00<00:00, 10347.94 examples/s]\n",
      "Generating test split: 100%|██████████| 232/232 [00:00<00:00, 14408.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vlm_dataset_wrong = load_dataset(\"CharlyR/vTikz-vlm_oracl_benchmark\",\"llama90bvision_wrong_solution\", split=\"test\")\n",
    "input_provided_dataset_wrong = load_dataset(\"CharlyR/vTikz-vlm_oracl_benchmark\",\"input_provided_gpt4o-mini_wrong_solution\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "vlm_df  = vlm_dataset_wrong.to_pandas()\n",
    "\n",
    "print(len(vlm_df[vlm_df[\"instruction_applied\"]==True]))\n",
    "\n",
    "input_provided_df  = input_provided_dataset_wrong.to_pandas()\n",
    "print(len(input_provided_df[input_provided_df[\"instruction_applied\"]==True]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
