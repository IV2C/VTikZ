import argparse
from enum import Enum
import pandas as pd
from tqdm import tqdm
from varbench.api.chat_api import ChatApi
from varbench.renderers import Renderer, TexRenderer, SvgRenderer, RendererException
from varbench.agents import LMMLoopAgent, SimpleLLMAgent, Agent, LMMAgent
from varbench.utils.patches import patches
from varbench.utils.parsing import get_config, get_first_code_block
from .api_generation import (
    VarbenchResponses
)
import os
from datasets import Dataset, Features, Sequence, Value, Image
from loguru import logger
from ..utils.prompts.simple_templates import (
    SYSTEM_PROMPT_GENERATION,
    SYSTEM_PROMPT_INSTRUCTIONS_SYNTHETIC,
    IT_PROMPT,
)


class ApiType(Enum):
    OPENAI = 0
    GROQ = 1


parser = argparse.ArgumentParser()

parser.add_argument(
    "--model",
    "-mg",
    type=str,
    required=True,
    help="Name of the model to use",
)

parser.add_argument(
    "--temperature",
    type=float,
    default=0.7,
    help="Temperature setting for model sampling",
)

parser.add_argument(
    "--folder",
    "-f",
    type=str,
    required=True,
    help="path to the folder that contains the code files to use as input",
)

parser.add_argument(
    "--number_gen",
    "-ng",
    type=int,
    required=False,
    default=5,
    help="The number of example of modifications generated by the llm(not certified to be exactly the one provided)",
)

parser.add_argument(
    "--api_url",
    type=str,
    default="https://api.openai.com/v1",
    help="URL of the openai completion compatible API",
)
parser.add_argument(
    "--passk", "-k", type=int, default=3, help="Number of generations per prompt"
)
parser.add_argument(
    "--api_key",
    type=str,
    default=None,
    help="API key for authentication, will default to the ENV variable OPENAI_API_KEY",
)


args = parser.parse_args()
temperature = args.temperature

model_type = args.model_type

folder_path = os.path.abspath(args.folder)
number_gen = args.number_gen

key_args: dict = {}
key_args["model_name"] = args.model
key_args["api_url"] = args.api_url
key_args["api_key"] = args.api_key
key_args["temperature"] = args.temperature
key_args["no_batch"] = True
key_args["n"] = args.passk

# loading model
#TODO add api and use it to generate instructions
agent = LMMLoopAgent(**key_args)

unfiltered_dataset = {}
for subset in tqdm(os.listdir(folder_path), position=0, desc="Treating the subsets"):
    # creating renderer
    renderer: Renderer = None
    match subset:
        case "tikz":
            renderer = TexRenderer()
        case "svg":
            renderer = SvgRenderer()
        case _:
            logger.warning(f"unsupported subset {subset}")
            continue
    current_subset = []
    for code_file in tqdm(
        os.listdir(os.path.join(folder_path, subset)),
        position=1,
        desc="Treating the files",
    ):
        file_path = os.path.join(folder_path, subset, code_file)
        with open(file_path, "r") as file:

            ##################"Generating instructions"###############
            content = file.read()

            messages = [
                {
                    "role": "system",
                    "content": SYSTEM_PROMPT_INSTRUCTIONS_SYNTHETIC,
                },
                {"role": "user", "content": content},
            ]
            # generating responses
            var_reponse_instructions = agent.compute(
                messages=messages,
                temperature=temperature,
                response_format=VarbenchResponses,
            )
            modifications = var_reponse_instructions.modifications
            ##################"Generating modifications"################
            all_images = []
            all_possible_codes = []
            for modification in tqdm(
                modifications, position=3, desc="Treating the modifications"
            ):

                # prompt
                user_instruction = IT_PROMPT.format(
                    instruction=modification.instruction,
                    content=var_reponse_instructions.commented_code,
                )

                messages = [
                    {
                        "role": "system",
                        "content": SYSTEM_PROMPT_GENERATION,
                    },
                    {"role": "user", "content": user_instruction},
                ]

                # generating
                possible_codes = agent.request(messages=messages)
                possible_codes = [
                    get_first_code_block(possible_code)
                    for possible_code in possible_codes
                ]
                # Making a list of images
                compiling_images = []
                treated_codes = (
                    set()
                )  # to ensure we don't compile the codes multiple times
                for code in possible_codes:
                    if code in treated_codes:
                        continue
                    treated_codes.add(code)
                    try:
                        current_image = renderer.from_string_to_image(code)
                        compiling_images.append(current_image)
                    except RendererException:
                        logger.info("Image rendering failed")
                    except Exception as e:
                        logger.warning("Other rendering")
                all_possible_codes.append(treated_codes)
                if len(compiling_images) == 0:
                    all_images.append(None)
                else:
                    all_images.append(compiling_images)

            ################ creating a dataset ##############
            for modification in zip(modifications, all_images, content, possible_codes):
                if not modification[1]:
                    continue
                current_patch = patches(content, modification[3])
                current_subset.append(
                    {
                        "id": modification[0].id,
                        "code": content,
                        "result_description": modification[0].result_description,
                        "instruction": modification[0].instruction,
                        "image_solution": modification[1],
                        "patches": current_patch,
                    }
                )
    if len(current_subset) > 0:
        unfiltered_dataset[subset] = current_subset

features = Features(
    {
        "id": Value("string"),
        "code": Value("string"),
        "instruction": Value("string"),
        "result_description": Value("string"),
        "patches": Sequence(Value("string")),
        "image_solution": Sequence(Image()),
    }
)

for subset in unfiltered_dataset:
    current_subset = pd.DataFrame(unfiltered_dataset[subset])
    dataset = Dataset.from_dict(pd.DataFrame(current_subset), features=features)
    dataset.push_to_hub(
        "CharlyR/varbench-synthetic", config_name=subset, split="unfiltered"
    )
