import argparse
from enum import Enum
import pandas as pd
from varbench.compilers import Compiler, TexCompiler, SvgCompiler
from varbench.compilers.compiler import CompilerException
from varbench.utils.diffs import diffs
from varbench.utils.parsing import get_first_code_block
from .api_generation import (
    groq_generation,
    groq_generation_format,
    openai_generation_format,
    openai_generation,
)
import os
from datasets import Dataset, Features, Sequence, Value, Image
from loguru import logger
from ..prompt_templates import (
    SYSTEM_PROMPT_GENERATION,
    SYSTEM_PROMPT_INSTRUCTIONS,
    IT_PROMPT,
)


class ApiType(Enum):
    OPENAI = 0
    GROQ = 1


def model_type_mapper(value):
    api_map = {"OPENAI": ApiType.OPENAI, "GROQ": ApiType.GROQ}
    if value.upper() not in api_map:
        raise argparse.ArgumentTypeError(f"Invalid API type: {value}")
    return api_map[value.upper()]


parser = argparse.ArgumentParser()

parser.add_argument(
    "--api_type",
    "-a",
    type=model_type_mapper,
    required=True,
    help="type of the api to use",
    default=ApiType.GROQ,
)
parser.add_argument(
    "--model",
    "-m",
    type=str,
    required=True,
    help="Name of the model to use",
)

parser.add_argument(
    "--temperature",
    type=float,
    default=0.7,
    help="Temperature setting for model sampling",
)

parser.add_argument(
    "--folder",
    "-f",
    type=str,
    required=True,
    help="path to the folder that contains the code files to use as input",
)

parser.add_argument(
    "--number_gen",
    "-n",
    type=int,
    required=False,
    default=1,
    help="The number of example of modifications generated by the llm(not certified to be exactly the one provided)",
)

args = parser.parse_args()

api_type = args.api_type
model = args.model
temperature = args.temperature
folder_path = os.path.abspath(args.folder)
number_gen = args.number_gen
match api_type:
    case ApiType.GROQ:
        instructor = groq_generation_format
        generator = groq_generation
    case ApiType.OPENAI:
        instructor = openai_generation_format
        generator = openai_generation

unfiltered_dataset = {}
for subset in os.listdir(folder_path):
    # creating compiler
    compiler: Compiler = None
    match subset:
        case "tikz":
            compiler = TexCompiler()
        case "svg":
            compiler = SvgCompiler()
    current_subset = []
    for code_file in os.listdir(os.path.join(folder_path, subset)):
        file_path = os.path.join(folder_path, subset, code_file)
        with open(file_path, "r") as file:

            ##################"Generating instructions"###############
            content = file.read()

            messages = [
                {
                    "role": "system",
                    "content": SYSTEM_PROMPT_INSTRUCTIONS.format(
                        number_generation=number_gen
                    ),
                },
                {"role": "user", "content": content},
            ]
            # generating responses
            modifications = instructor(
                messages=messages, model=model, temperature=temperature
            )

            ##################"Generating modifications"################
            all_images = []
            for modification in modifications:

                # prompt
                user_instruction = IT_PROMPT.format(
                    instruction=modification.instruction, content=content
                )

                messages = [
                    {
                        "role": "system",
                        "content": SYSTEM_PROMPT_GENERATION,
                    },
                    {"role": "user", "content": user_instruction},
                ]

                # generating
                possible_codes = generator(
                    messages=messages, model=model, temperature=temperature, n=5
                )
                possible_codes = [
                    get_first_code_block(possible_code)
                    for possible_code in possible_codes
                ]
                # Making a list of images
                compiling_images = []
                for code in possible_codes:
                    try:
                        current_image = compiler.compile_from_string(code)
                        compiling_images.append(current_image)
                    except CompilerException:
                        logger.info(
                            "Image compiling failed, code " + modification.result_code
                        )
                if len(compiling_images) == 0:
                    all_images.append(None)
                else:
                    all_images.append(compiling_images)

            ################ creating a dataset ##############
            for modification in zip(modifications, all_images, content,possible_codes):
                if not modification[1]:
                    continue
                current_diffs = diffs(content, modification[3])
                current_subset.append(
                    {
                        "id": modification[0].id,
                        "code": content,
                        "result_description": modification[0].result_description,
                        "instruction": modification[0].instruction,
                        "image_solution": modification[1],
                        "diffs": current_diffs,
                    }
                )
    if len(current_subset) > 0:
        unfiltered_dataset[subset] = current_subset

features = Features(
    {
        "id": Value("string"),
        "code": Value("string"),
        "instruction": Value("string"),
        "result_description": Value("string"),
        "diffs": Sequence(Value("string")),
        "image_solution": Sequence(Image()),
    }
)

for subset in unfiltered_dataset:
    current_subset = pd.DataFrame(unfiltered_dataset[subset])
    dataset = Dataset.from_dict(pd.DataFrame(current_subset), features=features)
    dataset.push_to_hub("CharlyR/varbench", config_name=subset, split="unfiltered")
